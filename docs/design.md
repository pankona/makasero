# AIエージェントの設計

## 概要

このAIエージェントは、GoogleのGenerative AI API（Gemini 2.5 Pro）を使用して、ユーザーの自然言語の指示をターミナルコマンドに変換し、実行する機能を提供します。

## 主要コンポーネント

### 1. メインアプリケーション (`main.go`)

- アプリケーションのエントリーポイント
- コマンドライン引数の処理
- 設定の読み込み
- AIエージェントの初期化と実行

### 2. AIエージェント

- Google Generative AI APIとの通信を担当
- ユーザーの入力を受け取り、適切なターミナルコマンドを生成
- 生成されたコマンドを実行し、結果をユーザーに返す

## 機能設計

### 1. コマンド生成

- ユーザーの自然言語の指示を受け取る
- Google Generative AI API（gemini-2.5-pro-exp-03-25）を使用して、指示をターミナルコマンドに変換
- 生成されたコマンドの安全性を確認
- ユーザーにコマンドを提示し、実行の確認を取る

### 2. コマンド実行

- ユーザーの確認後、生成されたコマンドを実行
- 実行結果（標準出力、標準エラー出力）を取得
- 実行結果をユーザーに表示

### 3. エラーハンドリング

- コマンド生成時のエラー処理
- コマンド実行時のエラー処理
- ユーザーへの適切なエラーメッセージの表示

## 設定

### 環境変数

- `GOOGLE_API_KEY`: Google Generative AI APIのAPIキー
- `MODEL_NAME`: 使用するGenerative AIモデルの名前（デフォルト: "gemini-2.5-pro-exp-03-25"）

## セキュリティ考慮事項

- 生成されたコマンドの安全性確認
- ユーザーによる実行確認の必須化
- APIキーの安全な管理

## 今後の拡張性

- 複数のコマンドの連続実行
- コマンド履歴の保存
- カスタムプロンプトのサポート
- 異なるAIモデルのサポート

## プロンプト設計

### 1. 初期バージョン（シンプル）

#### システムプロンプト

```
あなたは、ユーザーの指示をターミナルコマンドに変換するAIアシスタントです。
コマンドを実行する場合は、execCommand関数を使用してください。
```

#### ユーザープロンプトの例

```
ユーザー: カレントディレクトリのファイル一覧を表示して
AI: ls -la
```

### 2. 今後の拡張予定

以下の要素を段階的に追加していきます：

1. コマンドの説明
2. 安全性の警告
3. より詳細な動作指示
4. エラーハンドリングの指示
5. 複数コマンドの連続実行のサポート

### 3. プロンプトの進化方針

1. まずは最小限の機能で動作確認
2. 基本的なコマンド生成が安定したら、説明を追加
3. 安全性の確認機能を追加
4. より複雑な指示への対応を追加
5. エラーハンドリングの改善を追加

## エラーケース

1. APIキーが設定されていない場合
2. モデルが利用できない場合
3. コマンド生成に失敗した場合
4. コマンド実行に失敗した場合
5. ユーザーがコマンドの実行をキャンセルした場合
6. 関数呼び出しのパラメータが不正な場合
7. 関数呼び出しの結果が不正な場合
8. LLMが関数呼び出しを理解できない場合

## Function Calling 設計

### 1. 関数定義

```go
type FunctionDeclaration struct {
    Name        string   // 関数名
    Description string   // 関数の説明
    Parameters  *Schema  // パラメータのスキーマ
}

type Schema struct {
    Type        Type     // データ型
    Properties  map[string]*Schema  // プロパティの定義
    Required    []string // 必須パラメータ
}
```

### 2. 実行コマンド関数の定義

```go
{
    Name: "execCommand",
    Description: "ターミナルコマンドを実行し、その結果を返します",
    Parameters: &Schema{
        Type: TypeObject,
        Properties: map[string]*Schema{
            "command": {
                Type: TypeString,
                Description: "実行するコマンド",
            },
            "args": {
                Type: TypeArray,
                Items: &Schema{
                    Type: TypeString,
                },
                Description: "コマンドの引数",
            },
        },
        Required: []string{"command"},
    },
}
```

### 3. LLMとのやり取りの流れ

1. 初期化時
   - システムプロンプトと関数定義を設定
   - `FunctionCallingConfig`で`FunctionCallingMode`を`FunctionCallingAuto`に設定

2. ユーザー入力時の処理
   - ユーザーの自然言語の指示をLLMに送信
   - LLMは以下のいずれかを返す：
     - 自然言語の応答
     - `FunctionCall`オブジェクト（コマンド実行要求）

3. 関数呼び出し時の処理
   - `FunctionCall`を受け取った場合：
     - コマンドの安全性を確認
     - ユーザーに実行確認を求める
     - ユーザーの承認後、コマンドを実行
     - 実行結果を`FunctionResponse`としてLLMに返す
     - LLMは実行結果を踏まえて最終的な応答を生成

### 4. セキュリティ考慮事項の追加

- 関数呼び出しのパラメータの検証
- コマンド実行前のサニタイズ処理
- 関数呼び出しのログ記録
